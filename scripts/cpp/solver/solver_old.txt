#include <iostream>
#include <Eigen/Core>
#include <Eigen/Sparse>
using namespace Eigen;
double find_positive_root(const VectorXd& x, const SparseMatrix<double>& A, const VectorXd& p, const VectorXd& Ax, double xx) {
    VectorXd Ap = A * p;
    double xp = x.dot(p);
    double pp = p.dot(p);
    double pAp = p.dot(Ap);
    double xAp = x.dot(Ap);
    double xAx = x.dot(Ax);

    double a = (pAp) * (xp) - (xAp) * (pp);
    double b = (pAp) * (xx) - (xAx) * (pp);
    double c = (xAp) * (xx) - (xAx) * (xp);

    double delta = b * b - 4 * a * c;
    if (delta < 0) {
        return 0;
    }
    delta = sqrt(delta);
    double lambda1 = (-b + delta) / (2 * a);
    double lambda2 = (-b - delta) / (2 * a);
    if (lambda1 < 0 && lambda2 < 0) {
        return 0;
    }
    else if(lambda1 < 0) return lambda2;
    else if(lambda2 < 0) return lambda1;

    return lambda1 < lambda2 ? lambda1 : lambda2;

}

double compute_beta_FR(const VectorXd& r_new, const VectorXd& r_old) {
    return r_new.dot(r_new) / r_old.dot(r_old);
}


std::pair<double, VectorXd> find_eigenpair(const SparseMatrix<double>& A, int max_iter = 5000, double tol = 1e-28) {
    int N = A.rows();
    VectorXd x = VectorXd::Random(N).normalized();
    
    VectorXd Ax(N);
    VectorXd grad(N);
    VectorXd d(N);
    VectorXd r_new(N);
    VectorXd r_old(N);
    double xx = x.dot(x);
    Ax = A * x;
    grad = g(x, Ax, xx);
    double g0 = grad.dot(grad);
    d = -grad;
    r_new = d;
    
    for (int iter = 0; iter < max_iter; ++iter) {
        r_old = r_new;
        x = x + d*find_positive_root(x, A, d, Ax, xx);
        Ax = A * x;
        xx = x.dot(x);
        grad = g(x, Ax, xx);
        
        if (grad.dot(grad) < tol*g0) break;

        r_new = -grad;
        d = compute_beta_FR(r_new, r_old) * d + r_new;
        //cout << "Iteration " << iter << endl;
    }
    return {f(x, Ax, xx), x};
}


double f(const VectorXd& x, const VectorXd& Ax, double xx) {
    return x.dot(Ax) / xx;
}
VectorXd g(const VectorXd& x, const VectorXd& Ax, double xx) {
    return 2*(Ax - f(x, Ax, xx) * x)/ xx;
}

std::pair<double, VectorXd> find_eigenpair_constrained_dense(const MatrixXd& A, const VectorXd& X0, int max_iter = 100, double tol = 1e-6) {
    int N = A.rows();
    VectorXd x = X0.normalized();
    VectorXd z(N);
    VectorXd p(N);
    double a, b, c, d, delta, alfa, gamma, l, beta, g0;
    VectorXd Ax(N);
    VectorXd grad(N);
    Ax = A * x;
    l = f_constrained(x, Ax);
    p = g_constrained(x, Ax);
    g0 = p.norm();
    z = A * p;
    for (int iter = 0; iter < max_iter; ++iter) {
        a = z.dot(x);
        b = z.dot(p);
        c = x.dot(p);
        d = p.dot(p);
        delta = pow(l*d - b,2) - 4*(b*c - a*d)*(a-l*c);
        alfa = (l*d - b + sqrt(delta))/(2*(b*c - a*d));
        gamma = sqrt(1+2*c*alfa+d*pow(alfa, 2));
        l = (l+a*alfa)/(1+c*alfa); // new
        x = (x+alfa*p)/gamma;
        Ax = (Ax+alfa*z)/gamma;
        grad = Ax - l*x;
        if (grad.norm() < tol*l) {
            break;
        }
        beta = -(grad.dot(z))/(b);
        p = grad + beta*p;
        z = A*p;
    }
    return {f_constrained(x, Ax), x};

}

// Restituisce: pair<VectorXd, MatrixXd>
// VectorXd: I k autovalori di Ritz selezionati (ordinati)
// MatrixXd: I k autovettori di Ritz corrispondenti (coefficienti Y per la base S)
std::pair<VectorXd, MatrixXd> rayleigh_ritz_correct(const SparseMatrix<double>& A, const MatrixXd& S, int k) {
    // Calcola le matrici proiettate
    MatrixXd StS = S.transpose() * S;
    MatrixXd StAS = S.transpose() * (A * S); // Efficienza: calcola prima A*S se S è denso

    // Risolvi il problema agli autovalori generalizzato: StAS * Y = StS * Y * Lambda
    // Nota: Assicurati che StAS sia simmetrica (potrebbe richiedere (StAS + StAS.transpose())/2 per stabilità)
    GeneralizedSelfAdjointEigenSolver<MatrixXd> ges;
    ges.compute(StAS, StS); // Risolve A*y = lambda*B*y dove A=StAS, B=StS

    if (ges.info() != Success) {
        // Gestisci l'errore - il solver potrebbe fallire se StS è singolare
        // (le colonne di S sono linearmente dipendenti)
        std::cerr << "GeneralizedSelfAdjointEigenSolver failed!" << std::endl;
        // Potresti dover uscire o implementare una strategia di fallback
        // (es. ortogonalizzare S e riprovare, o ridurre la dimensione del blocco)
        throw std::runtime_error("Eigenvalue solver failed");
    }

    // ges.eigenvalues() restituisce autovalori ordinati in modo crescente.
    // ges.eigenvectors() restituisce gli autovettori corrispondenti Y come colonne.

    // Estrai i k più piccoli autovalori e i corrispondenti autovettori Y
    VectorXd ritz_values_k = ges.eigenvalues().head(k);
    MatrixXd ritz_vectors_Y_k = ges.eigenvectors().leftCols(k);

    return std::make_pair(ritz_values_k, ritz_vectors_Y_k);
}
std::pair<VectorXd, MatrixXd> lobpcg_correct(const SparseMatrix<double>& A, const MatrixXd& X0, int max_iter = 100, double tol = 1e-6) { // Rimosso max_iter_acgm ridondante
    int N = A.rows();
    int k = X0.cols();

    // --- Orthonormalize X0 (importante per il primo passo) ---
    // Householder QR decomposition
    HouseholderQR<MatrixXd> qr(X0);
    MatrixXd X = qr.householderQ() * MatrixXd::Identity(N, k);
    // ---------------------------------------------------------

    MatrixXd P = MatrixXd::Zero(N, k); // P è inizializzato a zero
    MatrixXd R;
    MatrixXd W;
    MatrixXd S;
    MatrixXd X_new;
    std::pair<VectorXd, MatrixXd> rr_pair; // Ora contiene VectorXd per gli autovalori

    // Calcolo iniziale di Ritz e residuo
    rr_pair = rayleigh_ritz_correct(A, X, k); // Usa X ortonormale iniziale
    // X = X * rr_pair.second; // Non serve riaggiornare X qui, è già la base usata
    MatrixXd Lambda = rr_pair.first.asDiagonal(); // Matrice diagonale degli autovalori
    R = A * X - X * Lambda; // Calcola il residuo iniziale

    for (int iter = 0; iter < max_iter; ++iter) {
         // --- Calcolo norma residuo (esempio) ---
         // Potresti voler usare una norma specifica B-norm se B non fosse identità
         double residual_norm = 0;
         for(int j=0; j<k; ++j) {
            // Norma del residuo per ciascun autovettore, o norma Frobenius totale?
            // Qui usiamo la norma Frobenius della matrice R
             residual_norm = R.norm(); // O R.col(j).norm() se vuoi convergenza individuale
         }
         std::cout << "Iteration " << iter << " | Residual Norm: " << residual_norm << std::endl;
         std::cout << "Eigenvalues: " << rr_pair.first.transpose() << std::endl; // Stampa il vettore

         if (residual_norm < tol) {
             break;
         }
         // --- Fine calcolo norma residuo ---


        // Precondizionamento (qui T=I) e ortogonalizzazione W (opzionale ma raccomandato)
        W = R; // T*W = R => W = R perché T=I

        // --- Ortogonalizzazione di W rispetto a X (B-ortogonalizzazione se B!=I) ---
        // Proietta W fuori dallo spazio di X: W = W - X * (X^T * W)  (poiché X^T*X = I)
        // Se X non fosse garantito ortonormale, servirebbe (X^T * X)^-1 * (X^T * W)
        MatrixXd XtW = X.transpose() * W;
        W = W - X * XtW;
        // Potrebbe essere necessaria una ri-ortogonalizzazione di W stesso se le sue colonne
        // diventano dipendenti, specialmente se si usa un precondizionatore.
        // Per B=I, T=I, potrebbe non essere strettamente necessario all'inizio.
        // ----------------------------------------------------------------------


        // Costruzione sottospazio S
        if (iter == 0) {
            S.resize(N, 2 * k);
            S.block(0, 0, N, k) = X;
            S.block(0, k, N, k) = W;
        } else {
             // --- Ortogonalizzazione di P rispetto a X ---
             MatrixXd XtP = X.transpose() * P;
             P = P - X * XtP;
             // --- Ortogonalizzazione di P rispetto a W (opzionale) ---
             // MatrixXd WtP = W.transpose() * P; // Serve W^T W se W non ortonormale
             // HouseholderQR<MatrixXd> qr_w(W); // QR per ortonormalizzare W
             // MatrixXd Q_w = qr_w.householderQ() * MatrixXd::Identity(N, k);
             // P = P - Q_w * (Q_w.transpose() * P);
             // ----------------------------------------------------------

            S.resize(N, 3 * k);
            S.block(0, 0, N, k) = X;
            S.block(0, k, N, k) = W;
            S.block(0, 2 * k, N, k) = P;
        }

        // Passo Rayleigh-Ritz sul sottospazio S
        rr_pair = rayleigh_ritz_correct(A, S, k); // Trova i k migliori nel sottospazio S
        VectorXd current_eigenvalues = rr_pair.first;
        MatrixXd Y = rr_pair.second; // Coefficienti per la base S

        // Aggiorna X, P, R
        // Y ha dimensioni S.cols() x k
        MatrixXd X_prev = X; // Salva il vecchio X per calcolare P dopo

        X = S * Y; // Aggiorna gli autovettori approssimati
        Lambda = current_eigenvalues.asDiagonal();
        R = A * X - X * Lambda; // Calcola il nuovo residuo

        // Aggiorna P: P_new = W*Y_w + P_old*Y_p
        // Y è partizionato [Y_x^T, Y_w^T, Y_p^T]^T (se iter > 0)
        // Y_x sono le prime k righe, Y_w le successive k, Y_p le ultime k (se esistono)
        if (iter == 0) { // S = [X_prev, W] -> Y è (2k x k)
            P = W * Y.block(k, 0, k, k); // P_new = W * Y_w
        } else { // S = [X_prev, W, P_prev] -> Y è (3k x k)
            P = W * Y.block(k, 0, k, k) + P * Y.block(2 * k, 0, k, k); // P_new = W*Y_w + P_prev*Y_p
        }
         // --- Assicurarsi che X sia ortonormale per il prossimo giro (opzionale ma buono) ---
         // HouseholderQR<MatrixXd> qr_x(X);
         // X = qr_x.householderQ() * MatrixXd::Identity(N, k);
         // Se fai questo, devi ricalcolare Lambda = X^T A X e poi R = AX - X Lambda
         // ---------------------------------------------------------------------------
    }
    // Ritorna l'ultimo set di autovalori e autovettori calcolati
    return std::make_pair(rr_pair.first, X); // Restituisce VectorXd e MatrixXd
}

// --- ATTENZIONE ---
// Gli include di Eigen sono necessari per la compilazione.
// Sono stati omessi come richiesto, ma devono essere presenti nel file C++.
// Assicurati che Eigen sia installato e accessibile dal tuo compilatore.
// Se A e B sono matrici sparse, usa Eigen::SparseMatrix<double> e
// decommenta <Eigen/SparseCore>. Le operazioni dovranno essere adattate.





std::pair<MatrixXd, MatrixXd> lobpcg(const SparseMatrix<double>& A, const MatrixXd& X0, int max_iter = 100, double tol = 1e-6, int max_iter_acgm = 1000) {
    int N = A.rows();
    int k = X0.cols();
    MatrixXd eigenvectors(N, k);
    MatrixXd M(k, k);
    MatrixXd X = X0;
    MatrixXd W(N, k);
    MatrixXd P(N, k);
    MatrixXd S;
    MatrixXd Q(N, N);
    VectorXd eigenvalues(k);
    VectorXd tmp(N);
    MatrixXd R(N, k);
    MatrixXd X_new(N, k);
    std::pair<MatrixXd, MatrixXd> rr_pair;

    rr_pair = rayleigh_ritz(A, X);
    X = X * rr_pair.first;
    
    R = A * X - X * rr_pair.second;


    for(int iter = 0; iter < max_iter_acgm; ++iter) {
        if (R.norm() < tol) {
            break;
        }
        W = R; //Solve BW = R
        if(iter==0) {
            S = MatrixXd(N, 2*k);
            S(all, seq(0, k-1)) = X;
            S(all, seq(k, 2*k-1)) = W;
        } else {
            S = MatrixXd(N, 3*k);
            S(all, seq(0, k-1)) = X;
            S(all, seq(k, 2*k-1)) = W;
            S(all, seq(2*k, 3*k-1)) = P;
        }


        rr_pair = rayleigh_ritz(A, S);
        X_new = S * rr_pair.first(all, seq(0, k-1));
        R = A * X_new - X_new * rr_pair.second(seq(0, k-1), seq(0, k-1));
        P = S(all, seq(k, S.cols()-1)) * rr_pair.first(seq(k, rr_pair.first.cols()-1), seq(0, k-1));
        X = X_new;

        
        std::cout << "Iteration " << iter << std::endl;
        std::cout << "Eigenvalues: " << rr_pair.second << std::endl;

        
    }
    return std::make_pair(rr_pair.second, X_new);
}

std::pair<VectorXd, MatrixXd> accelerated_cgm(const SparseMatrix<double>& A, const MatrixXd& X0, int max_iter = 100, double tol = 1e-6, int max_iter_acgm = 1000) {
    int N = A.rows();
    int k = X0.cols();
    MatrixXd eigenvectors(N, k);
    MatrixXd M(k, k);
    MatrixXd W = X0;
    MatrixXd W_copy = X0;
    MatrixXd Q(N, N);
    VectorXd eigenvalues(k);
    std::pair<double, VectorXd> pair;
    SelfAdjointEigenSolver<MatrixXd> es;
    VectorXd sum(N);
    VectorXd tmp(N);
    std::vector<std::pair<double, VectorXd>> pairs(k);

    for(int iter = 0; iter < max_iter_acgm; ++iter) {
        for(int i = 0; i < k; ++i) {
            Q.setIdentity();
            if(i > 0) {
                Q -=  (W(all, seq(0, i-1)) * W(all, seq(0, i-1)).transpose());
            }
            pair = find_eigenpair_constrained_dense(Q*A*Q, Q*VectorXd::Random(N), max_iter, tol);
            W(all, i) = pair.second;
            eigenvalues(i) = pair.first;
            tmp = pair.second;
            pairs[i] = std::make_pair(eigenvalues(i), tmp);
            
        }
        
        M = W.transpose() * A * W;
        es = SelfAdjointEigenSolver<MatrixXd>(M);
        eigenvectors = es.eigenvectors();
        W_copy = MatrixXd(W);
        //for(int i = 0; i < k; ++i) {
            //sum = VectorXd::Zero(N);
            //for(int j = 0; j < k; ++j) {
                //sum += es.eigenvectors()(j, i) * W_copy(all, j);
            //}
            //W(all, i) = sum;

        //}
        W = W_copy * es.eigenvectors();
        
        std::cout << "Iteration " << iter << std::endl;
        std::cout << "Eigenvalues: " << eigenvalues << std::endl;
        std::cout << "Diag eigenvalules: " << es.eigenvalues() << std::endl;

        
    }
    return std::pair<VectorXd, MatrixXd>(es.eigenvalues(), W);
}
